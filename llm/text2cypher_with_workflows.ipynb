{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b50e216-6915-4644-b4c7-434a6fa2f843",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet llama-index-core llama-index-utils-workflow llama-index-llms-openai llama-index-graph-stores-neo4j "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5e873d91-0953-483c-ad27-922986b36ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomazbratanic/anaconda3/lib/python3.11/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from neo4j.exceptions import CypherSyntaxError\n",
    "\n",
    "from llama_index.core import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Literal, Union, Optional\n",
    "\n",
    "from llama_index.core.workflow import (\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Event,\n",
    "    Context,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7012b2a4-de4f-4a64-9945-8f68a79870d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.graph_stores.neo4j import Neo4jPropertyGraphStore\n",
    "\n",
    "graph_store = Neo4jPropertyGraphStore(\n",
    "    username=\"recommendations\",\n",
    "    password=\"recommendations\",\n",
    "    database=\"recommendations\",\n",
    "    url=\"neo4j+s://demo.neo4jlabs.com:7687\",\n",
    "    enhanced_schema=True,\n",
    "    create_indexes=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a18727dc-376b-4f76-a052-7ad57ae1a182",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-\"\n",
    "llm = OpenAI(model=\"gpt-4-turbo\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "2cf99343-8559-4f98-ab8b-355febf59649",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Guardrail(BaseModel):\n",
    "    \"\"\"Guardrail\"\"\"\n",
    "\n",
    "    decision: Literal[\"movie\", \"end\"] = Field(\n",
    "        description=\"Decision on whether the question is related to movies\"\n",
    "        \n",
    "    )\n",
    "guardrails_system_prompt = \"\"\"As an intelligent assistant, your primary objective is to decide whether a given question is related to movies or not.\n",
    "If the question is related to movies, output \"movie\". Otherwise, output \"end\".\n",
    "To make this decision, assess the content of the question and determine if it refers to any movie, actor, director, film industry,\n",
    "or related topics. Provide only the specified output: \"movie\" or \"end\".\"\"\"\n",
    "# Refine Prompt\n",
    "chat_refine_msgs = [\n",
    "    (\n",
    "        \"system\",\n",
    "        guardrails_system_prompt,\n",
    "    ),\n",
    "    (\"user\", \"The question is: {question}\"),\n",
    "]\n",
    "guardrails_template = ChatPromptTemplate.from_messages(chat_refine_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "e618e42c-6ee1-434e-be80-986b5bfe607f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SubqueriesOutput(BaseModel):\n",
    "    \"\"\"Defines the output format for transforming a question into parallel-optimized retrieval steps.\"\"\"\n",
    "    \n",
    "    plan: List[List[str]] = Field(description=(\"\"\"A list of query groups where:\n",
    "        - Each group (inner list) contains queries that can be executed in parallel\n",
    "        - Groups are ordered by dependency (earlier groups must be executed before later ones)\n",
    "        - Each query must be a specific information retrieval request\n",
    "        - No reasoning or comparison tasks, only data fetching queries\"\"\"))\n",
    "\n",
    "subqueries_system = \"\"\"You are a query planning optimizer. Your task is to break down complex questions into efficient, parallel-optimized retrieval steps. Focus ONLY on information retrieval queries, not analysis or reasoning steps.\n",
    "\n",
    "Key Requirements:\n",
    "- Group queries that can be executed in parallel into the same list\n",
    "- Order groups based on data dependencies\n",
    "- Include ONLY specific information retrieval queries\n",
    "- Exclude reasoning tasks, comparisons, or analysis steps\n",
    "- Prioritize queries that can be executed first and in parallel\n",
    "\n",
    "For simple, directly answerable questions, return a single query in a single group.\n",
    "\n",
    "Example 1:\n",
    "User: \"What was the impact of the 2008 financial crisis on Bank of America's stock price and employee count?\"\n",
    "Assistant: [\n",
    "    # Group 1 - These can be fetched in parallel\n",
    "    [\n",
    "        \"What was Bank of America's stock price history from 2007 to 2009?\",\n",
    "        \"What was Bank of America's total employee count in 2007?\",\n",
    "        \"What was Bank of America's total employee count in 2009?\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "Example 2:\n",
    "User: \"Compare the performance of Tesla's Model 3 with BMW's competing models in terms of range and acceleration.\"\n",
    "Assistant: [\n",
    "    # Group 1 - Basic specs can be fetched in parallel\n",
    "    [\n",
    "        \"What is the EPA range of the Tesla Model 3?\",\n",
    "        \"What is the 0-60 mph acceleration time of the Tesla Model 3?\",\n",
    "        \"What BMW models compete directly with the Tesla Model 3?\"\n",
    "    ],\n",
    "    # Group 2 - Depends on knowing competing models from group 1\n",
    "    [\n",
    "        \"What is the EPA range of each identified BMW competitor model?\",\n",
    "        \"What is the 0-60 mph acceleration time of each identified BMW competitor model?\"\n",
    "    ]\n",
    "]\n",
    "\n",
    "Remember:\n",
    "- Focus on data retrieval only\n",
    "- Maximize parallel execution opportunities\n",
    "- Maintain necessary sequential ordering\n",
    "- Keep queries specific and self-contained\n",
    "- Prioritize independent queries first\"\"\"\n",
    "\n",
    "query_decompose_msgs = [\n",
    "    (\"system\", subqueries_system),\n",
    "    (\"user\", \"{question}\")\n",
    "]\n",
    "\n",
    "subquery_template = ChatPromptTemplate.from_messages(query_decompose_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "cbf05240-d619-499c-83fe-dd1f917c55dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def guardrails_step(question):\n",
    "    guardrails_output = (\n",
    "        llm.as_structured_llm(Guardrail)\n",
    "        .complete(guardrails_template.format(question=question))\n",
    "        .raw\n",
    "    ).decision\n",
    "    if guardrails_output == 'end':\n",
    "        context = \"The question is not about movies or their case, so I cannot answer this question\"\n",
    "        return {\"next_event\": \"generate_final_answer\", \"arguments\": {\"context\": context, \"question\": question}}\n",
    "    # Refactor into separate step\n",
    "    queries_output = (\n",
    "        llm.as_structured_llm(SubqueriesOutput)\n",
    "        .complete(subquery_template.format(question=question))\n",
    "        .raw\n",
    "    ).plan\n",
    "    return {\"next_event\": \"generate_cypher\", \"arguments\": {\"plan\": queries_output, \"question\": question}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "8314df30-cf3c-4441-92c1-ae88f9d0a672",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'next_event': 'generate_cypher',\n",
       " 'arguments': {'plan': [['How many movies has Leonardo DiCaprio appeared in?',\n",
       "    \"Who is the director of Tom Hanks' most critically acclaimed movie?\"],\n",
       "   ['Who has co-starred most frequently with the identified director?'],\n",
       "   ['How many movies has the most frequent co-star of the identified director appeared in?']],\n",
       "  'question': \"Who has appeared in more movies: Leonardo DiCaprio or the actor who has co-starred most frequently with the director of Tom Hanks' most critically acclaimed movie??\"}}"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guardrails_step(\"Who has appeared in more movies: Leonardo DiCaprio or the actor who has co-starred most frequently with the director of Tom Hanks' most critically acclaimed movie??\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fd6844fa-f5ad-42c2-8312-43541410b7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "embed_model = OpenAIEmbedding(model=\"text-embedding-3-small\")\n",
    "\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"question\": \"How many artists are there?\",\n",
    "        \"query\": \"MATCH (a:Person)-[:ACTED_IN]->(:Movie) RETURN count(DISTINCT a)\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which actors played in the movie Casino?\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Casino'})<-[:ACTED_IN]-(a) RETURN a.name\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"How many movies has Tom Hanks acted in?\",\n",
    "        \"query\": \"MATCH (a:Person {name: 'Tom Hanks'})-[:ACTED_IN]->(m:Movie) RETURN count(m)\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"List all the genres of the movie Schindler's List\",\n",
    "        \"query\": \"MATCH (m:Movie {title: 'Schindler's List'})-[:IN_GENRE]->(g:Genre) RETURN g.name\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which actors have worked in movies from both the comedy and action genres?\",\n",
    "        \"query\": \"MATCH (a:Person)-[:ACTED_IN]->(:Movie)-[:IN_GENRE]->(g1:Genre), (a)-[:ACTED_IN]->(:Movie)-[:IN_GENRE]->(g2:Genre) WHERE g1.name = 'Comedy' AND g2.name = 'Action' RETURN DISTINCT a.name\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Which directors have made movies with at least three different actors named 'John'?\",\n",
    "        \"query\": \"MATCH (d:Person)-[:DIRECTED]->(m:Movie)<-[:ACTED_IN]-(a:Person) WHERE a.name STARTS WITH 'John' WITH d, COUNT(DISTINCT a) AS JohnsCount WHERE JohnsCount >= 3 RETURN d.name\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Identify movies where directors also played a role in the film.\",\n",
    "        \"query\": \"MATCH (p:Person)-[:DIRECTED]->(m:Movie), (p)-[:ACTED_IN]->(m) RETURN m.title, p.name\",\n",
    "    },\n",
    "    {\n",
    "        \"question\": \"Find the actor with the highest number of movies in the database.\",\n",
    "        \"query\": \"MATCH (a:Actor)-[:ACTED_IN]->(m:Movie) RETURN a.name, COUNT(m) AS movieCount ORDER BY movieCount DESC LIMIT 1\",\n",
    "    },\n",
    "]\n",
    "\n",
    "few_shot_nodes = []\n",
    "for line in examples:\n",
    "    few_shot_nodes.append(TextNode(text=f\"{{'query':{line['query']}, 'question': {line['question']}))\"))\n",
    "\n",
    "few_shot_index = VectorStoreIndex(few_shot_nodes, embed_model=embed_model)\n",
    "few_shot_retriever = few_shot_index.as_retriever(similarity_top_k=5)\n",
    "\n",
    "\n",
    "def get_fewshots(question):\n",
    "    return [el.text for el in few_shot_retriever.retrieve(question)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "c0597674-4e7d-4723-8094-3f1adeee3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_system = \"\"\"Given an input question, convert it to a Cypher query. No pre-amble.\n",
    "Do not wrap the response in any backticks or anything else. Respond with a Cypher statement only!\"\"\"\n",
    "\n",
    "generate_user = \"\"\"You are a Neo4j expert. Given an input question, create a syntactically correct Cypher query to run.\n",
    "Do not wrap the response in any backticks or anything else. Respond with a Cypher statement only!\n",
    "Here is the schema information\n",
    "{schema}\n",
    "\n",
    "Below are a number of examples of questions and their corresponding Cypher queries.\n",
    "\n",
    "{fewshot_examples}\n",
    "\n",
    "User input: {question}\n",
    "Cypher query:\"\"\"\n",
    "\n",
    "generate_cypher_msgs = [\n",
    "    (\n",
    "        \"system\",\n",
    "        generate_system,\n",
    "    ),\n",
    "    (\"user\", generate_user),\n",
    "]\n",
    "\n",
    "text2cypher_prompt = ChatPromptTemplate.from_messages(generate_cypher_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "4ec54fde-6995-4823-9150-b9798763d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = graph_store.get_schema_str(exclude_types=[\"Actor\", \"Director\"])\n",
    "\n",
    "async def generate_cypher(subquery):\n",
    "    fewshot_examples = get_fewshots(subquery)\n",
    "    resp = await llm.achat(text2cypher_prompt.format_messages(question=subquery, schema=schema, fewshot_examples=fewshot_examples))\n",
    "    return resp.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "7804a532-64a0-41dc-830b-c50bf75d75fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_cypher_system = \"\"\"\n",
    "You are a Cypher expert reviewing a statement written by a junior developer.\n",
    "\"\"\"\n",
    "\n",
    "validate_cypher_user = \"\"\"You must check the following:\n",
    "\n",
    "1. **Logical alignment:** Does the Cypher statement clearly align with the question being asked?  \n",
    "2. **Structural correctness:** Does the structure of the Cypher statement ensure it can retrieve the expected answer without errors?  \n",
    "3. **Execution readiness:** Are there any definitive issues that would prevent the query from executing correctly (e.g., incomplete, malformed, or syntactically invalid statements)?\n",
    "\n",
    "### Examples of valid errors:\n",
    "- The Cypher statement does not match the intent of the question. For example, the query retrieves products when the question asks for customers.  \n",
    "- The query is structurally incomplete or malformed, such as missing `RETURN` clauses or incorrect `MATCH` syntax.  \n",
    "- The query lacks sufficient filtering or conditions to retrieve the desired data, such as omitting constraints or necessary properties in the query.\n",
    "\n",
    "### Schema:\n",
    "{schema}\n",
    "\n",
    "### The question is:\n",
    "{question}\n",
    "\n",
    "### The Cypher statement is:\n",
    "{cypher}\n",
    "\n",
    "**Important:** Focus on objective, clear-cut errors that directly affect the query's correctness or execution. Avoid overly nitpicking minor ambiguities or assumptions that could be valid in context. For example, do not flag the following as an error:\n",
    "\n",
    "- \"The query does not correctly identify the most critically acclaimed item. It assumes the first item in the result list is correct without checking for ties.\"  \n",
    "\n",
    "Such scenarios should only be flagged if the question's intent explicitly contradicts the query logic or if the ambiguity leads to an actual failure to retrieve the expected result.\n",
    "\n",
    "Errors must be indisputable and clearly incorrect with no room for debate.\"\"\"\n",
    "\n",
    "validate_cypher_msgs = [\n",
    "    (\n",
    "        \"system\",\n",
    "        validate_cypher_system,\n",
    "    ),\n",
    "    (\"user\", validate_cypher_user),\n",
    "]\n",
    "\n",
    "validate_cypher_prompt = ChatPromptTemplate.from_messages(validate_cypher_msgs)\n",
    "\n",
    "class Property(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents a filter condition based on a specific node property in a graph in a Cypher statement.\n",
    "    \"\"\"\n",
    "\n",
    "    node_label: str = Field(\n",
    "        description=\"The label of the node to which this property belongs.\"\n",
    "    )\n",
    "    property_key: str = Field(description=\"The key of the property being filtered.\")\n",
    "    property_value: str = Field(\n",
    "        description=\"The value that the property is being matched against.\"\n",
    "    )\n",
    "\n",
    "\n",
    "class ValidateCypherOutput(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents the validation result of a Cypher query's output,\n",
    "    including any errors and applied filters.\n",
    "    \"\"\"\n",
    "\n",
    "    errors: Optional[List[str]] = Field(\n",
    "        description=\"A list of clear, objective issues in the Cypher statement that directly prevent it from answering the question logically or executing correctly.\"\n",
    "    )\n",
    "    filters: Optional[List[Property]] = Field(\n",
    "        description=\"A list of property-based filters applied in the Cypher statement.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "7795a143-f6e5-4198-bd9d-3efc1d98a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.graph_stores.neo4j import CypherQueryCorrector, Schema\n",
    "\n",
    "# Cypher query corrector is experimental\n",
    "corrector_schema = [\n",
    "    Schema(el[\"start\"], el[\"type\"], el[\"end\"])\n",
    "    for el in graph_store.get_schema().get(\"relationships\")\n",
    "]\n",
    "cypher_query_corrector = CypherQueryCorrector(corrector_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ba0a4ea0-63be-4309-b5ce-75dd9229a4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_cypher(question, cypher):\n",
    "    \"\"\"\n",
    "    Validates the Cypher statements and maps any property values to the database.\n",
    "    \"\"\"\n",
    "    errors = []\n",
    "    mapping_errors = []\n",
    "    # Check for syntax errors\n",
    "    try:\n",
    "        graph_store.structured_query(f\"EXPLAIN {cypher}\")\n",
    "    except CypherSyntaxError as e:\n",
    "        errors.append(e.message)\n",
    "    # Experimental feature for correcting relationship directions\n",
    "    corrected_cypher = cypher_query_corrector(cypher)\n",
    "    if not corrected_cypher:\n",
    "        errors.append(\"The generated Cypher statement doesn't fit the graph schema\")\n",
    "    # Use LLM to find additional potential errors and get the mapping for values\n",
    "    llm_output =   (\n",
    "        llm.as_structured_llm(ValidateCypherOutput)\n",
    "        .complete(validate_cypher_prompt.format(question=question, cypher=cypher, schema=schema))\n",
    "        .raw\n",
    "    )\n",
    "    print(f\"LLM:{llm_output}\")\n",
    "    if llm_output.errors:\n",
    "        errors.extend(llm_output.errors)\n",
    "    if llm_output.filters:\n",
    "        for filter in llm_output.filters:\n",
    "            # Do mapping only for string values\n",
    "            if (\n",
    "                not [\n",
    "                    prop\n",
    "                    for prop in graph_store.get_schema()[\"node_props\"][\n",
    "                        filter.node_label\n",
    "                    ]\n",
    "                    if prop[\"property\"] == filter.property_key\n",
    "                ][0][\"type\"]\n",
    "                == \"STRING\"\n",
    "            ):\n",
    "                continue\n",
    "            print(f\"Mapping: {filter}\")\n",
    "            mapping = graph_store.structured_query(\n",
    "                f\"MATCH (n:{filter.node_label}) WHERE toLower(n.`{filter.property_key}`) = toLower($value) RETURN 'yes' LIMIT 1\",\n",
    "                {\"value\": filter.property_value},\n",
    "            )\n",
    "            if not mapping:\n",
    "                print(\n",
    "                    f\"Missing value mapping for {filter.node_label} on property {filter.property_key} with value {filter.property_value}\"\n",
    "                )\n",
    "                mapping_errors.append(\n",
    "                    f\"Missing value mapping for {filter.node_label} on property {filter.property_key} with value {filter.property_value}\"\n",
    "                )\n",
    "    if mapping_errors:\n",
    "        next_action = \"end\"\n",
    "    elif errors:\n",
    "        next_action = \"correct_cypher\"\n",
    "    else:\n",
    "        next_action = \"execute_cypher\"\n",
    "\n",
    "    return {\n",
    "        \"next_action\": next_action,\n",
    "        \"cypher_statement\": corrected_cypher,\n",
    "        \"cypher_errors\": errors,\n",
    "        \"mapping_errors\": mapping_errors,\n",
    "        \"steps\": [\"validate_cypher\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "44d23e86-bbba-42c4-97f7-412a6a93ac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_cypher_system = \"\"\"You are a Cypher expert reviewing a statement written by a junior developer. \n",
    "You need to correct the Cypher statement based on the provided errors. No pre-amble.\"\n",
    "Do not wrap the response in any backticks or anything else. Respond with a Cypher statement only!\"\"\"\n",
    "\n",
    "correct_cypher_user = \"\"\"Check for invalid syntax or semantics and return a corrected Cypher statement.\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "\n",
    "Note: Do not include any explanations or apologies in your responses.\n",
    "Do not wrap the response in any backticks or anything else.\n",
    "Respond with a Cypher statement only!\n",
    "\n",
    "Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "\n",
    "The question is:\n",
    "{question}\n",
    "\n",
    "The Cypher statement is:\n",
    "{cypher}\n",
    "\n",
    "The errors are:\n",
    "{errors}\n",
    "\n",
    "Corrected Cypher statement: \"\"\"\n",
    "\n",
    "# Correct cypher\n",
    "correct_cypher_msgs = [\n",
    "    (\n",
    "        \"system\",\n",
    "        correct_cypher_system,\n",
    "    ),\n",
    "    (\"user\", correct_cypher_user),\n",
    "]\n",
    "\n",
    "correct_cypher_prompt = ChatPromptTemplate.from_messages(generate_cypher_msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9dfe2255-8146-4082-8ada-78b5ff95a79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def correct_cypher(subquery, cypher, errors):\n",
    "    resp = await llm.achat(correct_cypher_prompt.format_messages(question=subquery, schema=schema, errors=errors))\n",
    "    return resp.message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "1b2562aa-64ec-42c8-b1f4-dfa285c26751",
   "metadata": {},
   "outputs": [],
   "source": [
    "information_check_system = \"\"\"You are an expert assistant that evaluates whether a set of subqueries, their results, any existing condensed information, and the current query plan provide enough details to answer a given question. Your task is to:\n",
    "\n",
    "1. Analyze if the available information is sufficient to answer the original question: \"{original_question}\".\n",
    "2. Review the remaining steps in the query plan (if any) to determine if they:\n",
    "   - Should be retained as is.\n",
    "   - Need modification to address gaps.\n",
    "   - Can be skipped because the required information is already available.\n",
    "   - Should be reorganized for optimized execution (e.g., parallel processing).\n",
    "\n",
    "### Process:\n",
    "\n",
    "#### 1. Analyze the Original Question\n",
    "   - Identify the key pieces of information required to fully answer the question.\n",
    "   - Break the question into smaller components if it involves multiple aspects.\n",
    "\n",
    "#### 2. Review Available Information\n",
    "   - Examine the subqueries, their results, and any provided condensed information.\n",
    "   - Assess if they collectively address all components of the question.\n",
    "\n",
    "#### 3. Identify Information Gaps\n",
    "   - Compare the requirements from the question against the available information.\n",
    "   - Highlight any missing details or incomplete data that must be retrieved to form a complete answer.\n",
    "   - If any critical subqueries fail to produce results essential for answering the question:\n",
    "     - Document the missing information in the **dynamic notebook**.\n",
    "     - Mark the task as **unsolvable** due to the missing data.\n",
    "     - Do not produce a modified query plan, as the question cannot be answered with the available or fetchable information.\n",
    "\n",
    "#### 4. Update and Refine the **Dynamic Notebook**\n",
    "   - Treat the condensed information as a **central knowledge base**:\n",
    "     - Continuously update it with key details from subquery results.\n",
    "     - Integrate new data to close gaps and establish connections between facts.\n",
    "   - Ensure the notebook reflects the current state of knowledge, including any identified gaps or failed subqueries.\n",
    "   - Document explicitly if the task is unsolvable due to missing information.\n",
    "\n",
    "#### 5. Modify the Query Plan (If Solvable)\n",
    "   - If sufficient information is available:\n",
    "     - Generate a concise and accurate answer to the question.\n",
    "     - Specify which remaining steps (if any) in the query plan can be skipped.\n",
    "   - If information is insufficient but fetchable:\n",
    "     - Suggest additional subqueries to retrieve the missing details.\n",
    "     - Ensure new subqueries are designed specifically to fill identified gaps.\n",
    "     - Organize all subqueries into parallel-executable groups wherever possible.\n",
    "     - Maintain sequential steps only when strict data dependencies exist.\n",
    "   - If critical gaps exist that cannot be resolved due to failed subqueries, do not modify the query plan and clearly state why the task cannot be completed.\n",
    "\n",
    "### Key Guidelines:\n",
    "- **Focus Only on Information Retrieval**: Limit query plans to fetching data and avoid reasoning/analysis tasks.\n",
    "- **Optimize for Parallel Execution**: Group queries into parallelizable blocks to reduce execution time.\n",
    "- **Maintain Sequential Order Only When Necessary**: Use sequential steps only when results of one query depend on another.\n",
    "- **Centralize Knowledge**:\n",
    "   - Use the dynamic notebook to consolidate all available information.\n",
    "   - Ensure it remains the authoritative source for answering the question and guiding further steps.\n",
    "   - Explicitly document unsolvable tasks if critical information is missing.\n",
    "\"\"\"\n",
    "\n",
    "information_check_user = \"\"\"\n",
    "Subqueries and their results:  \n",
    "{subqueries}  \n",
    "Existing dynamic notebook:  \n",
    "{dynamic_notebook}\n",
    "Current remaining plan (if any):\n",
    "{plan}\n",
    "Original question: {question}  \n",
    "\"\"\"\n",
    "\n",
    "information_check_msgs = [\n",
    "    (\n",
    "        \"system\",\n",
    "        information_check_system,\n",
    "    ),\n",
    "    (\"user\", information_check_user),\n",
    "]\n",
    "\n",
    "information_check_prompt = ChatPromptTemplate.from_messages(information_check_msgs)\n",
    "\n",
    "class IFOutput(BaseModel):\n",
    "    \"\"\"\n",
    "    Represents the output of an information sufficiency evaluation process. \n",
    "    Contains either a condensed summary of the available information or additional subqueries needed to answer the original question.\n",
    "    \"\"\"\n",
    "\n",
    "    dynamic_notebook: str = Field(\n",
    "        description=\"A continuously updated and refined summary integrating subquery results and condensed information. Serves as the central knowledge base to address the original question and guide further subqueries if necessary.\"\n",
    "    )\n",
    "    modified_plan: Optional[List[List[str]]] = Field(\n",
    "        description=\"Modified version of the remaining plan steps. Each group contains queries that can be executed in parallel. Null if no remaining plan exists, all gaps have been addressed, or the task is unsolvable due to missing critical information.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "15837b79-6416-425d-8eb3-7e1d91af267c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_subqueries_for_prompt(information_checks: list) -> str:\n",
    "    \"\"\"\n",
    "    Converts a list of InformationCheck objects into a string that can be added to a prompt.\n",
    "    \n",
    "    Args:\n",
    "        information_checks (List[InformationCheck]): List of information checks to process.\n",
    "    \n",
    "    Returns:\n",
    "        str: A formatted string representing subqueries and their results.\n",
    "    \"\"\"\n",
    "    subqueries_and_results = []\n",
    "    \n",
    "    for check in information_checks:\n",
    "        # Extract the first result if available, otherwise use \"No result available.\"\n",
    "        result = (\n",
    "            check.database_output[0] if check.database_output else \"No result available.\"\n",
    "        )\n",
    "        subqueries_and_results.append(\n",
    "            f\"- Subquery: {check.subquery}\\n  Result: {result}\"\n",
    "        )\n",
    "    \n",
    "    return \"\\n\".join(subqueries_and_results)\n",
    "\n",
    "def information_check(subquery_events, original_question, dynamic_notebook, plan):\n",
    "    subqueries = format_subqueries_for_prompt(subquery_events)\n",
    "    print(f\"Before: {dynamic_notebook}\")\n",
    "    print(f\"Plan: {plan}\")\n",
    "    llm_output =   (\n",
    "        llm.as_structured_llm(IFOutput)\n",
    "        .complete(information_check_prompt.format(subqueries=subqueries, original_question=original_question, dynamic_notebook=dynamic_notebook, plan=plan))\n",
    "        .raw\n",
    "    )\n",
    "    print(f\"After: {llm_output.dynamic_notebook}\")\n",
    "    print(f\"New Plan: {llm_output.modified_plan}\")\n",
    "    return {'dynamic_notebook': llm_output.dynamic_notebook, 'modified_plan': llm_output.modified_plan}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ed70406c-c95b-4e29-a863-cc29c14a89c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_answer_system = \"\"\"You are a highly intelligent assistant trained to provide concise and accurate answers. You will be given a context and a user question. Your task is to analyze the context and answer the user question based on the information provided in the context. If the context lacks sufficient information to answer the question, inform the user and suggest what additional details are needed.\n",
    "\n",
    "Focus solely on the context to form your response. Avoid making assumptions or using external knowledge unless explicitly stated in the context.\n",
    "Ensure the final answer is clear, relevant, and directly addresses the userâ€™s question.\n",
    "If the question is ambiguous, ask clarifying questions to ensure accuracy before proceeding.\"\"\"\n",
    "\n",
    "final_answer_user = \"\"\"\n",
    "Based on this context:\n",
    "{context}\n",
    "\n",
    "Answer the following question:\n",
    "<question>\n",
    "{question}\n",
    "</question>\n",
    "\n",
    "Provide your answer based on the context above explain your reasoning.\n",
    "If clarification or additional information is needed, explain why and specify what is required.\n",
    "\"\"\"\n",
    "\n",
    "final_answer_msgs = [\n",
    "    (\n",
    "        \"system\",\n",
    "        final_answer_system,\n",
    "    ),\n",
    "    (\"user\", final_answer_user),\n",
    "]\n",
    "\n",
    "final_answer_prompt = ChatPromptTemplate.from_messages(final_answer_msgs)\n",
    "\n",
    "async def generate_final_answer(question, context):\n",
    "    resp = await llm.achat(final_answer_prompt.format_messages(question=question, context=context))\n",
    "    return resp.message.content                 \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "0ee5da9c-679f-4dd5-b99f-2d63334fd8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenerateCypher(Event):\n",
    "    subquery: str\n",
    "    \n",
    "class ValidateCypher(Event):\n",
    "    subquery: str\n",
    "    generated_cypher: str\n",
    "\n",
    "class CorrectCypher(Event):\n",
    "    cypher: str\n",
    "    subquery: str\n",
    "    errors: List[str]\n",
    "\n",
    "class ExecuteCypher(Event):\n",
    "    validated_cypher: str\n",
    "    subquery: str\n",
    "\n",
    "class InformationCheck(Event):\n",
    "    cypher: str\n",
    "    subquery: str\n",
    "    database_output: list\n",
    "    \n",
    "class GenerateFinalAnswer(Event):\n",
    "    context: str\n",
    "\n",
    "class ConcurrentFlow(Workflow):\n",
    "    @step\n",
    "    async def start(self, ctx: Context, ev: StartEvent) -> GenerateCypher | GenerateFinalAnswer:\n",
    "        original_question = ev.input\n",
    "        await ctx.set(\"original_question\", original_question)\n",
    "        await ctx.set(\"dynamic_notebook\", \"\")\n",
    "        await ctx.set(\"subqueries_cypher_history\", {})\n",
    "        guardrails_output = guardrails_step(original_question)\n",
    "        if guardrails_output.get(\"next_event\") == \"generate_final_answer\":\n",
    "            context = \"The question is not about movies or cast, so I cannot answer the question\"\n",
    "            return GenerateFinalAnswer(context=context)\n",
    "\n",
    "        # store in global context \n",
    "        subqueries = guardrails_output[\"arguments\"].get(\"plan\")\n",
    "        await ctx.set(\"count_of_subqueries\", len(subqueries[0])) #we use this in ctx.collect()\n",
    "        await ctx.set(\"plan\", subqueries[1:]) #we use this in information check\n",
    "        # Send events\n",
    "        for subquery in subqueries[0]:\n",
    "            print(subquery)\n",
    "            ctx.send_event(GenerateCypher(subquery=subquery))\n",
    "\n",
    "    @step(num_workers=4)\n",
    "    async def generate_cypher_step(self, ctx: Context, ev: GenerateCypher) -> ValidateCypher:\n",
    "        print(\"Running generate_cypher \", ev.subquery)\n",
    "        generated_cypher = await generate_cypher(ev.subquery)\n",
    "        return ValidateCypher(subquery=ev.subquery, generated_cypher=generated_cypher)\n",
    "\n",
    "    @step(num_workers=4)\n",
    "    async def validate_cypher_step(self, ctx: Context, ev: ValidateCypher) -> GenerateFinalAnswer | ExecuteCypher | CorrectCypher:\n",
    "        print(\"Running validate_cypher \", ev)\n",
    "        results = validate_cypher(ev.subquery, ev.generated_cypher)\n",
    "        print(results)\n",
    "        if results['next_action'] == \"end\": # DB value mapping\n",
    "            return GenerateFinalAnswer(context=str(results[\"mapping_errors\"]))\n",
    "        if results['next_action'] == \"execute_cypher\":\n",
    "            return ExecuteCypher(subquery=ev.subquery, validated_cypher=ev.generated_cypher)\n",
    "        if results['next_action'] == \"correct_cypher\":\n",
    "            return CorrectCypher(subquery=ev.subquery, cypher=ev.generated_cypher, errors=results['cypher_errors'])\n",
    "\n",
    "    @step(num_workers=4)\n",
    "    async def correct_cypher_step(self, ctx: Context, ev: CorrectCypher) -> ValidateCypher:\n",
    "        print(\"Running validate_cypher \", ev)\n",
    "        results = await correct_cypher(ev.subquery, ev.cypher, ev.errors)\n",
    "        return ValidateCypher(subquery=ev.subquery, generated_cypher=results)\n",
    "    \n",
    "    @step\n",
    "    async def execute_cypher_step(self, ctx: Context, ev: ExecuteCypher) -> InformationCheck:\n",
    "        # wait until we receive all events\n",
    "        print(\"Running execute_cypher_step \", ev)\n",
    "        database_output = graph_store.structured_query(ev.validated_cypher)\n",
    "        return InformationCheck(subquery=ev.subquery, cypher=ev.validated_cypher, database_output=database_output)\n",
    "\n",
    "    @step\n",
    "    async def information_check_step(self, ctx: Context, ev: InformationCheck) -> GenerateCypher | GenerateFinalAnswer:\n",
    "        # wait until we receive all events\n",
    "        print(\"Running information_check_step\", ev)\n",
    "        # retrieve from context\n",
    "        number_of_subqueries = await ctx.get(\"count_of_subqueries\")\n",
    "        result = ctx.collect_events(ev, [InformationCheck] * number_of_subqueries)\n",
    "        if result is None:\n",
    "            return None\n",
    "        # Add executed cypher statements to global state\n",
    "        subqueries_cypher_history = await ctx.get(\"subqueries_cypher_history\")\n",
    "        new_subqueries_cypher = {\n",
    "                item.subquery: {\n",
    "                    \"cypher\": item.cypher,\n",
    "                    \"database_output\": item.database_output\n",
    "                } for item in result\n",
    "            }\n",
    "        await ctx.set(\"subqueries_cypher_history\", {**subqueries_cypher_history, **new_subqueries_cypher})\n",
    "\n",
    "        original_question = await ctx.get(\"original_question\")\n",
    "        dynamic_notebook = await ctx.get(\"dynamic_notebook\")\n",
    "        plan = await ctx.get(\"plan\")\n",
    "\n",
    "        # Do the information check\n",
    "        \n",
    "        data = information_check(result, original_question, dynamic_notebook, plan)\n",
    "        # Go fetch additional information if needed\n",
    "        if data.get(\"modified_plan\"):\n",
    "            await ctx.set(\"count_of_subqueries\", len(data['modified_plan'][0])) # this is used for ctx.collect()\n",
    "            await ctx.set(\"dynamic_notebook\", data[\"dynamic_notebook\"])\n",
    "            await ctx.set(\"plan\", data.get(\"modified_plan\")[1:])\n",
    "            for subquery in data[\"modified_plan\"][0]:\n",
    "                ctx.send_event(GenerateCypher(subquery=subquery))\n",
    "        else:\n",
    "            return GenerateFinalAnswer(context=data['dynamic_notebook'])\n",
    "\n",
    "    @step\n",
    "    async def final_answer(self, ctx: Context, ev: GenerateFinalAnswer) -> StopEvent:\n",
    "        original_question = await ctx.get(\"original_question\")\n",
    "        subqueries_cypher_history = await ctx.get(\"subqueries_cypher_history\")\n",
    "        # wait until we receive all events\n",
    "        print(\"Running final_answer \", ev)\n",
    "        resp = await generate_final_answer(original_question, ev.context)\n",
    "        return StopEvent(result={\"text\":resp, \"subqueries_cypher_history\": subqueries_cypher_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "01ba2699-c0e4-4518-a0d6-3d7bd40113b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running step start\n",
      "How many movies has Leonardo DiCaprio made?\n",
      "How many movies has Tom Hanks made?\n",
      "Step start produced no event\n",
      "Running step generate_cypher_step\n",
      "Running generate_cypher  How many movies has Leonardo DiCaprio made?\n",
      "Running step generate_cypher_step\n",
      "Running generate_cypher  How many movies has Tom Hanks made?\n",
      "Step generate_cypher_step produced event ValidateCypher\n",
      "Running step validate_cypher_step\n",
      "Running validate_cypher  subquery='How many movies has Tom Hanks made?' generated_cypher=\"MATCH (p:Person {name: 'Tom Hanks'})-[:ACTED_IN]->(m:Movie) RETURN count(m)\"\n",
      "LLM:errors=None filters=[Property(node_label='Person', property_key='name', property_value='Tom Hanks')]\n",
      "Mapping: node_label='Person' property_key='name' property_value='Tom Hanks'\n",
      "{'next_action': 'execute_cypher', 'cypher_statement': \"MATCH (p:Person {name: 'Tom Hanks'})-[:ACTED_IN]->(m:Movie) RETURN count(m)\", 'cypher_errors': [], 'mapping_errors': [], 'steps': ['validate_cypher']}\n",
      "Step validate_cypher_step produced event ExecuteCypher\n",
      "Running step execute_cypher_step\n",
      "Running execute_cypher_step  validated_cypher=\"MATCH (p:Person {name: 'Tom Hanks'})-[:ACTED_IN]->(m:Movie) RETURN count(m)\" subquery='How many movies has Tom Hanks made?'\n",
      "Step execute_cypher_step produced event InformationCheck\n",
      "Running step information_check_step\n",
      "Running information_check_step cypher=\"MATCH (p:Person {name: 'Tom Hanks'})-[:ACTED_IN]->(m:Movie) RETURN count(m)\" subquery='How many movies has Tom Hanks made?' database_output=[{'count(m)': 38}]\n",
      "Step information_check_step produced no event\n",
      "Step generate_cypher_step produced event ValidateCypher\n",
      "Running step validate_cypher_step\n",
      "Running validate_cypher  subquery='How many movies has Leonardo DiCaprio made?' generated_cypher=\"MATCH (p:Person {name: 'Leonardo DiCaprio'})-[:ACTED_IN]->(m:Movie) RETURN count(m)\"\n",
      "LLM:errors=None filters=[Property(node_label='Person', property_key='name', property_value='Leonardo DiCaprio')]\n",
      "Mapping: node_label='Person' property_key='name' property_value='Leonardo DiCaprio'\n",
      "{'next_action': 'execute_cypher', 'cypher_statement': \"MATCH (p:Person {name: 'Leonardo DiCaprio'})-[:ACTED_IN]->(m:Movie) RETURN count(m)\", 'cypher_errors': [], 'mapping_errors': [], 'steps': ['validate_cypher']}\n",
      "Step validate_cypher_step produced event ExecuteCypher\n",
      "Running step execute_cypher_step\n",
      "Running execute_cypher_step  validated_cypher=\"MATCH (p:Person {name: 'Leonardo DiCaprio'})-[:ACTED_IN]->(m:Movie) RETURN count(m)\" subquery='How many movies has Leonardo DiCaprio made?'\n",
      "Step execute_cypher_step produced event InformationCheck\n",
      "Running step information_check_step\n",
      "Running information_check_step cypher=\"MATCH (p:Person {name: 'Leonardo DiCaprio'})-[:ACTED_IN]->(m:Movie) RETURN count(m)\" subquery='How many movies has Leonardo DiCaprio made?' database_output=[{'count(m)': 24}]\n",
      "Before: \n",
      "Plan: []\n",
      "After: Leonardo DiCaprio has made 24 movies, while Tom Hanks has made 38 movies.\n",
      "New Plan: None\n",
      "Step information_check_step produced event GenerateFinalAnswer\n",
      "Running step final_answer\n",
      "Running final_answer  context='Leonardo DiCaprio has made 24 movies, while Tom Hanks has made 38 movies.'\n",
      "Step final_answer produced event StopEvent\n",
      "{'text': 'Tom Hanks has made more movies than Leonardo DiCaprio. According to the context, Tom Hanks has made 38 movies, while Leonardo DiCaprio has made 24 movies.', 'subqueries_cypher_history': {'How many movies has Tom Hanks made?': {'cypher': \"MATCH (p:Person {name: 'Tom Hanks'})-[:ACTED_IN]->(m:Movie) RETURN count(m)\", 'database_output': [{'count(m)': 38}]}, 'How many movies has Leonardo DiCaprio made?': {'cypher': \"MATCH (p:Person {name: 'Leonardo DiCaprio'})-[:ACTED_IN]->(m:Movie) RETURN count(m)\", 'database_output': [{'count(m)': 24}]}}}\n"
     ]
    }
   ],
   "source": [
    "w = ConcurrentFlow(timeout=25, verbose=True)\n",
    "result = await w.run(input=\"Who made more movies, Leonardo DiCaprio or Tom Hanks?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "97362343-ff0d-40d2-a679-c487dbcb58b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who is Tom Hanks' most frequent co-actor?\n",
      "Running generate_cypher  Who is Tom Hanks' most frequent co-actor?\n",
      "Running validate_cypher  subquery=\"Who is Tom Hanks' most frequent co-actor?\" generated_cypher='MATCH (h:Person {name: \"Tom Hanks\"})-[:ACTED_IN]->(m:Movie)<-[:ACTED_IN]-(coActor:Person) WHERE coActor.name <> \"Tom Hanks\" RETURN coActor.name, COUNT(*) AS moviesTogether ORDER BY moviesTogether DESC LIMIT 1'\n",
      "LLM:errors=None filters=[Property(node_label='Person', property_key='name', property_value='Tom Hanks')]\n",
      "Mapping: node_label='Person' property_key='name' property_value='Tom Hanks'\n",
      "{'next_action': 'execute_cypher', 'cypher_statement': 'MATCH (h:Person {name: \"Tom Hanks\"})-[:ACTED_IN]->(m:Movie)<-[:ACTED_IN]-(coActor:Person) WHERE coActor.name <> \"Tom Hanks\" RETURN coActor.name, COUNT(*) AS moviesTogether ORDER BY moviesTogether DESC LIMIT 1', 'cypher_errors': [], 'mapping_errors': [], 'steps': ['validate_cypher']}\n",
      "Running execute_cypher_step  validated_cypher='MATCH (h:Person {name: \"Tom Hanks\"})-[:ACTED_IN]->(m:Movie)<-[:ACTED_IN]-(coActor:Person) WHERE coActor.name <> \"Tom Hanks\" RETURN coActor.name, COUNT(*) AS moviesTogether ORDER BY moviesTogether DESC LIMIT 1' subquery=\"Who is Tom Hanks' most frequent co-actor?\"\n",
      "Running information_check_step cypher='MATCH (h:Person {name: \"Tom Hanks\"})-[:ACTED_IN]->(m:Movie)<-[:ACTED_IN]-(coActor:Person) WHERE coActor.name <> \"Tom Hanks\" RETURN coActor.name, COUNT(*) AS moviesTogether ORDER BY moviesTogether DESC LIMIT 1' subquery=\"Who is Tom Hanks' most frequent co-actor?\" database_output=[{'coActor.name': 'Tim Allen', 'moviesTogether': 4}]\n",
      "Before: \n",
      "Plan: [['How many movies has Leonardo DiCaprio made?', \"How many movies has Tom Hanks' most frequent co-actor made?\"]]\n",
      "After: **Dynamic Notebook Update:**\n",
      "\n",
      "- **Tom Hanks' Most Frequent Co-actor:** Tim Allen, with 4 movies together.\n",
      "\n",
      "**Information Gaps Identified:**\n",
      "- The number of movies Leonardo DiCaprio has made is unknown.\n",
      "- The number of movies Tim Allen has made is unknown.\n",
      "\n",
      "These gaps are critical for determining who made more movies, Leonardo DiCaprio or Tim Allen.\n",
      "New Plan: [['How many movies has Leonardo DiCaprio made?', \"How many movies has Tom Hanks' most frequent co-actor made?\"]]\n",
      "Running generate_cypher  How many movies has Leonardo DiCaprio made?\n",
      "Running generate_cypher  How many movies has Tom Hanks' most frequent co-actor made?\n",
      "Running validate_cypher  subquery='How many movies has Leonardo DiCaprio made?' generated_cypher=\"MATCH (p:Person {name: 'Leonardo DiCaprio'})-[:ACTED_IN]->(m:Movie) RETURN count(m)\"\n",
      "LLM:errors=None filters=[Property(node_label='Person', property_key='name', property_value='Leonardo DiCaprio')]\n",
      "Mapping: node_label='Person' property_key='name' property_value='Leonardo DiCaprio'\n",
      "{'next_action': 'execute_cypher', 'cypher_statement': \"MATCH (p:Person {name: 'Leonardo DiCaprio'})-[:ACTED_IN]->(m:Movie) RETURN count(m)\", 'cypher_errors': [], 'mapping_errors': [], 'steps': ['validate_cypher']}\n",
      "Running execute_cypher_step  validated_cypher=\"MATCH (p:Person {name: 'Leonardo DiCaprio'})-[:ACTED_IN]->(m:Movie) RETURN count(m)\" subquery='How many movies has Leonardo DiCaprio made?'\n",
      "Running information_check_step cypher=\"MATCH (p:Person {name: 'Leonardo DiCaprio'})-[:ACTED_IN]->(m:Movie) RETURN count(m)\" subquery='How many movies has Leonardo DiCaprio made?' database_output=[{'count(m)': 24}]\n",
      "Running validate_cypher  subquery=\"How many movies has Tom Hanks' most frequent co-actor made?\" generated_cypher='MATCH (h:Person {name: \"Tom Hanks\"})-[:ACTED_IN]->(m:Movie)<-[:ACTED_IN]-(coActor:Person) WHERE coActor.name <> \"Tom Hanks\" WITH coActor, COUNT(*) AS moviesTogether ORDER BY moviesTogether DESC LIMIT 1 MATCH (coActor)-[:ACTED_IN]->(movies) RETURN coActor.name, COUNT(movies) as movieCount'\n",
      "LLM:errors=['The Cypher statement is missing a semicolon to separate the two MATCH clauses, which may cause a syntax error or unexpected behavior during execution.', 'The RETURN clause should specify the properties of the movies node to count distinct movies, as it currently counts all relationships, potentially leading to inaccurate results.'] filters=[Property(node_label='Person', property_key='name', property_value='Tom Hanks'), Property(node_label='Person', property_key='name', property_value='Tom Hanks')]\n",
      "Mapping: node_label='Person' property_key='name' property_value='Tom Hanks'\n",
      "Mapping: node_label='Person' property_key='name' property_value='Tom Hanks'\n",
      "{'next_action': 'correct_cypher', 'cypher_statement': 'MATCH (h:Person {name: \"Tom Hanks\"})-[:ACTED_IN]->(m:Movie)<-[:ACTED_IN]-(coActor:Person) WHERE coActor.name <> \"Tom Hanks\" WITH coActor, COUNT(*) AS moviesTogether ORDER BY moviesTogether DESC LIMIT 1 MATCH (coActor)-[:ACTED_IN]->(movies) RETURN coActor.name, COUNT(movies) as movieCount', 'cypher_errors': ['The Cypher statement is missing a semicolon to separate the two MATCH clauses, which may cause a syntax error or unexpected behavior during execution.', 'The RETURN clause should specify the properties of the movies node to count distinct movies, as it currently counts all relationships, potentially leading to inaccurate results.'], 'mapping_errors': [], 'steps': ['validate_cypher']}\n",
      "Running validate_cypher  cypher='MATCH (h:Person {name: \"Tom Hanks\"})-[:ACTED_IN]->(m:Movie)<-[:ACTED_IN]-(coActor:Person) WHERE coActor.name <> \"Tom Hanks\" WITH coActor, COUNT(*) AS moviesTogether ORDER BY moviesTogether DESC LIMIT 1 MATCH (coActor)-[:ACTED_IN]->(movies) RETURN coActor.name, COUNT(movies) as movieCount' subquery=\"How many movies has Tom Hanks' most frequent co-actor made?\" errors=['The Cypher statement is missing a semicolon to separate the two MATCH clauses, which may cause a syntax error or unexpected behavior during execution.', 'The RETURN clause should specify the properties of the movies node to count distinct movies, as it currently counts all relationships, potentially leading to inaccurate results.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in callback Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-9affdbe465e3', bound_args=<BoundArgumen...t coactor?'})>, instance=<__main__.Con...t 0x376970a10>, context=<_contextvars...t 0x37696cc00>)(<WorkflowHand... 30 seconds')>) at /Users/tomazbratanic/anaconda3/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273\n",
      "handle: <Handle Dispatcher.span.<locals>.wrapper.<locals>.handle_future_result(span_id='Workflow.run...-9affdbe465e3', bound_args=<BoundArgumen...t coactor?'})>, instance=<__main__.Con...t 0x376970a10>, context=<_contextvars...t 0x37696cc00>)(<WorkflowHand... 30 seconds')>) at /Users/tomazbratanic/anaconda3/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py:273>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tomazbratanic/anaconda3/lib/python3.11/asyncio/events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/tomazbratanic/anaconda3/lib/python3.11/site-packages/llama_index/core/instrumentation/dispatcher.py\", line 285, in handle_future_result\n",
      "    raise exception\n",
      "  File \"/Users/tomazbratanic/anaconda3/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py\", line 445, in _run_workflow\n",
      "    raise WorkflowTimeoutError(msg)\n",
      "llama_index.core.workflow.errors.WorkflowTimeoutError: Operation timed out after 30 seconds\n"
     ]
    },
    {
     "ename": "WorkflowTimeoutError",
     "evalue": "Operation timed out after 30 seconds",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mWorkflowTimeoutError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[169], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m w \u001b[38;5;241m=\u001b[39m ConcurrentFlow(timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 2\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m w\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWho made more movies, Leonardo di Caprio or Tom Hanks most frequent coactor?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/llama_index/core/workflow/workflow.py:445\u001b[0m, in \u001b[0;36mWorkflow.run.<locals>._run_workflow\u001b[0;34m()\u001b[0m\n\u001b[1;32m    442\u001b[0m         ctx\u001b[38;5;241m.\u001b[39mwrite_event_to_stream(StopEvent())\n\u001b[1;32m    444\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOperation timed out after \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 445\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m WorkflowTimeoutError(msg)\n\u001b[1;32m    447\u001b[0m     result\u001b[38;5;241m.\u001b[39mset_result(ctx\u001b[38;5;241m.\u001b[39m_retval)\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mWorkflowTimeoutError\u001b[0m: Operation timed out after 30 seconds"
     ]
    }
   ],
   "source": [
    "w = ConcurrentFlow(timeout=30, verbose=False)\n",
    "result = await w.run(input=\"Who made more movies, Leonardo di Caprio or Tom Hanks most frequent coactor?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143e4ba1-0950-41fa-919e-efbbaa7d3010",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = ConcurrentFlow(timeout=60, verbose=True)\n",
    "result = await w.run(input=\"Who has appeared in more movies: Leonardo DiCaprio or the actor who has co-starred most frequently with the director of Tom Hanks' most critically acclaimed movie??\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5797cb48-f34e-418d-94bd-366920d3ecd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = ConcurrentFlow(timeout=30, verbose=False)\n",
    "result = await w.run(input=\"What\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f455f31f-2a02-4e84-b75a-bdd951f147aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "joke_flow_recent.html\n",
      "<class 'NoneType'>\n",
      "<class '__main__.ValidateCypher'>\n",
      "<class '__main__.InformationCheck'>\n",
      "<class 'llama_index.core.workflow.events.StopEvent'>\n",
      "<class '__main__.ValidateCypher'>\n",
      "<class '__main__.GenerateCypher'>\n",
      "<class '__main__.GenerateFinalAnswer'>\n",
      "<class '__main__.GenerateCypher'>\n",
      "<class '__main__.GenerateFinalAnswer'>\n",
      "<class '__main__.GenerateFinalAnswer'>\n",
      "<class '__main__.ExecuteCypher'>\n",
      "<class '__main__.CorrectCypher'>\n",
      "joke_flow_recenst.html\n"
     ]
    }
   ],
   "source": [
    "from llama_index.utils.workflow import (\n",
    "    draw_all_possible_flows,\n",
    "    draw_most_recent_execution,\n",
    ")\n",
    "\n",
    "draw_most_recent_execution(w, filename=\"joke_flow_recent.html\")\n",
    "draw_all_possible_flows(w, filename=\"joke_flow_recenst.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2000dd85-f6be-46a6-8d04-f45750a3f698",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
