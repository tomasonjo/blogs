{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/tomasonjo/blogs/blob/master/youtube/video2graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDqgx3RrK3KA",
    "outputId": "33553409-740e-49b9-e9c2-48ca12591dd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /home/tomaz/anaconda3/lib/python3.8/site-packages (0.27.2)\n",
      "Requirement already satisfied: youtube-transcript-api in /home/tomaz/anaconda3/lib/python3.8/site-packages (0.5.0)\n",
      "Requirement already satisfied: neo4j in /home/tomaz/.local/lib/python3.8/site-packages (4.4.3)\n",
      "Requirement already satisfied: retry in /home/tomaz/anaconda3/lib/python3.8/site-packages (0.9.2)\n",
      "Requirement already satisfied: pytz in /home/tomaz/anaconda3/lib/python3.8/site-packages (from neo4j) (2021.1)\n",
      "Requirement already satisfied: aiohttp in /home/tomaz/anaconda3/lib/python3.8/site-packages (from openai) (3.8.1)\n",
      "Requirement already satisfied: tqdm in /home/tomaz/.local/lib/python3.8/site-packages (from openai) (4.64.0)\n",
      "Requirement already satisfied: requests>=2.20 in /home/tomaz/anaconda3/lib/python3.8/site-packages (from openai) (2.28.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/tomaz/anaconda3/lib/python3.8/site-packages (from requests>=2.20->openai) (2.0.12)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/tomaz/anaconda3/lib/python3.8/site-packages (from requests>=2.20->openai) (1.26.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/tomaz/anaconda3/lib/python3.8/site-packages (from requests>=2.20->openai) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/tomaz/anaconda3/lib/python3.8/site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Requirement already satisfied: decorator>=3.4.2 in /home/tomaz/anaconda3/lib/python3.8/site-packages (from retry) (5.0.5)\n",
      "Requirement already satisfied: py<2.0.0,>=1.4.26 in /home/tomaz/anaconda3/lib/python3.8/site-packages (from retry) (1.10.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/tomaz/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/tomaz/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (6.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/tomaz/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (1.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/tomaz/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (1.7.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/tomaz/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/tomaz/anaconda3/lib/python3.8/site-packages (from aiohttp->openai) (20.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openai youtube-transcript-api neo4j retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "stf9vu_mdlBn"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "from retry import retry\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "pd.set_option(\"display.max_colwidth\", 150)\n",
    "\n",
    "openai.api_key = \"OPENAI_KEY\"\n",
    "\n",
    "uri = \"bolt://18.207.186.117:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"magazine-scream-roadside\"\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_query(query, params={}):\n",
    "    with driver.session() as session:\n",
    "        result = session.run(query, params)\n",
    "        return pd.DataFrame([r.values() for r in result], columns=result.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Knowledge Graph from Video Transcripts with GPT-4\n",
    "## Use GPT-4 as a domain expert to help you extract knowledge from a video transcript\n",
    "\n",
    "A couple of days ago, I got access to GPT-4. The first thing that came to my mind was to test how well it performs as an information extraction model, where the task is to extract relevant entities and relationships from a given text. I have already played around with GPT-3.5 a bit. The most important thing I noticed is that we don't want to use the GPT endpoint as an entity linking solution or have it come up with any other external references like citations, as it likes to hallucinate those types of information.\n",
    "\n",
    "However, a great thing about GPT-3 or GPT-4 is that it performs well in various domains. For example, we can use it to extract people, organizations, or locations from a text. However, I feel that competing against dedicated NLP models is not where the GPT models shine (although they perform well). Instead, the strength of GPT models is in their ability to generalize and be used in other domains where other open-sourced models fail due to their limited training data.\n",
    "\n",
    "My friend Michael Hunger gave me a great idea to test the GPT-4 on extracting information from a nature documentary. I always liked the deep sea documentary as the ecosystem and animals are so vastly different from terrestrial ones. Therefore, I decided to test GPT-4 information extraction capabilities on an underwater documentary. Additionally, I don't know of any open-source NLP models trained to detect relationships between sea plants and creatures. So, a deep sea documentary makes for an excellent example of using a GPT-4 to construct a knowledge graph.\n",
    "\n",
    "## Dataset\n",
    "\n",
    "The most accessible place to find documentaries is YouTube. Although the GPT-4 is multi-modal (supports video, audio, and text), the current version of the endpoint only supports text inputs. Therefore, we will analyze a video's audio transcript, not the video itself.\n",
    "We will be analyzing the transcript of the following documentary.\n",
    "\n",
    "https://www.youtube.com/watch?v=nrI483C5Tro\n",
    "\n",
    "First of all, I like the topic of the documentary. Secondly, extracting captions from a YouTube video is effortless as we don't have to use any audio2text models at all. However, converting audio to text with all the available models on HuggingFace or even OpenAI's Whisper shouldn't be a big problem. Thirdly, this video has captions that are not auto-generated. At first, I tried to extract information from auto-generated captions on YouTube, but I learned that they might not be the best input. So if you can, avoid using auto-generated YouTube captions.\n",
    "\n",
    "The captions can be retrieved straightforwardly with the YouTube Transcript/Subtitle library. All we have to do is to provide the video id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "j_bDji05UECS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'text': 'water the liquid that oceans are made of', 'start': 5.46, 'duration': 4.38}, {'text': 'and it fills endless depths only few will venture\\xa0\\xa0', 'start': 12.24, 'duration': 4.92}, {'text': 'out into the endless open ocean\\xa0\\nof this vast underwater world', 'start': 17.16, 'duration': 4.68}]\n"
     ]
    }
   ],
   "source": [
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "\n",
    "video_id = \"nrI483C5Tro\"\n",
    "transcript = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "print(transcript[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The captions are split into chunks, which can be used as video subtitles. Therefore, the start and duration information is provided along with the text. You might also notice a couple of special characters like \\xa0 and \\n .\n",
    "\n",
    "Even though GPT-4 endpoint support up to 8k tokens per request, more is needed to process the whole transcript in a single request. Therefore, we need to split the transcript into several parts. So, I decided to split the transcript into multiple parts, where the end of the part is determined when there are five or more seconds of no captions, announcing a brief pause in narration. Using this approach, I aim to keep all connecting text together and retain relevant information in a single section.\n",
    "\n",
    "I used the following code to group the transcript into several sections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MVS38lqEaRbu"
   },
   "outputs": [],
   "source": [
    "# Split into sections and include start and end timestamps\n",
    "sections = []\n",
    "current_section = \"\"\n",
    "start_time = None\n",
    "previous_end = 0\n",
    "pause_threshold = 5\n",
    "\n",
    "for line in transcript:\n",
    "    if current_section and (line[\"start\"] - previous_end > pause_threshold):\n",
    "        # If there is a pause greater than 5s, we deem the end of section\n",
    "        end_time = line[\"start\"]\n",
    "        sections.append(\n",
    "            {\n",
    "                \"text\": current_section.strip(),\n",
    "                \"start_time\": start_time,\n",
    "                \"end_time\": end_time,\n",
    "            }\n",
    "        )\n",
    "        current_section = \"\"\n",
    "        start_time = None\n",
    "    else:\n",
    "        # If this is the start of a new section, record the start time\n",
    "        if not start_time:\n",
    "            start_time = line[\"start\"]\n",
    "\n",
    "        # Add the line to the current paragraph\n",
    "        clean_text = line[\"text\"].replace(\"\\n\", \" \").replace(\"\\xa0\", \" \")\n",
    "        current_section += \" \".join(clean_text.split()) + \" \"\n",
    "        # Tag the end of the dialogue\n",
    "        previous_end = line[\"start\"] + line[\"duration\"]\n",
    "\n",
    "# If there's a paragraph left at the end, add it to the list of paragraphs\n",
    "if current_section:\n",
    "    end_time = transcript[-1][\"start\"] + transcript[-1][\"duration\"]\n",
    "    sections.append(\n",
    "        {\n",
    "            \"text\": current_section.strip().replace(\"\\n\", \" \").replace(\"\\xa0\", \" \"),\n",
    "            \"start_time\": start_time,\n",
    "            \"end_time\": end_time,\n",
    "        }\n",
    "    )\n",
    "# Remove empty paragraphs\n",
    "sections = [p for p in sections if p[\"text\"]]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To evaluate results of the section grouping, I printed the following information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dXp7PwoJVJe9",
    "outputId": "c3247dc1-eb60-40c5-c84e-34908b1dee28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sections: 77\n",
      "Max characters per section: 1267\n"
     ]
    }
   ],
   "source": [
    "# Number of paragraphs\n",
    "print(f\"Number of sections: {len(sections)}\")\n",
    "print(f\"Max characters per section: {max([len(el['text']) for el in sections])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dy0sucRDaUPA",
    "outputId": "f7637a7d-dcff-427a-a474-2f1c3ce52190"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'water the liquid that oceans are made of and it fills endless depths only few will venture out into the endless open ocean of this vast underwater world most of the ocean inhabitants live in the city as it were like human societies very close together with friendly Neighbors and nasty cotenants while dangerous robbers lurk around at the edge of town',\n",
       " 'start_time': 5.46,\n",
       " 'end_time': 49.08}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sections[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 77 sections, with the longest having 1267 characters in it. We are nowhere near the GPT-4 token limit, and I think the above approach delivers a nice text granularity, at least in this example.\n",
    "Information extraction with GPT-4\n",
    "\n",
    "GPT-4 endpoint is optimized for chat but works well for traditional completion tasks. As the model is optimized for conversation, we can provide a system message, which helps set the assistant's behavior along with any previous messages that can help keep the context of the dialogue. However, as we are using the GPT-4 endpoint for a text completion task, we will not provide any previous messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "GDqh6TY7dxCq"
   },
   "outputs": [],
   "source": [
    "def parse_entities_and_relationships(input_str):\n",
    "    # Parse the input string\n",
    "    entities = []\n",
    "    relationships = []\n",
    "    entity_mode = True\n",
    "    # Skip the first line\n",
    "    for line in input_str.split(\"\\n\")[1:]:\n",
    "        if line == \"relationships\":\n",
    "            entity_mode = False\n",
    "        elif line:\n",
    "            if entity_mode:\n",
    "                # Make sure the rel is in correct format\n",
    "                # GPT-4 sometimes returns n/a when no entities are found\n",
    "                if len(line.split(\", \")) != 3:\n",
    "                    continue\n",
    "                entities.append(line.split(\", \"))\n",
    "            else:\n",
    "                # Make sure the rel is in correct format\n",
    "                # GPT-4 sometimes returns n/a when no rels are found\n",
    "                if len(line.split(\", \")) != 3:\n",
    "                    continue\n",
    "                relationships.append(line.split(\", \"))\n",
    "    return entities, relationships"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The GPT-4 is prompted to extract relevant entities from a given text. Additionally, I added some constraints that distances and time durations should not be treated as entities. The extracted entities should contain their name, type, and the sentiment. As for the relationships, they should be provided in a form of a triple. I added some hints that the model should follow Wikipedia schema type, which makes the extracted relationship types a bit more standardized. I learned that it is always good to provide an example of an output as otherwise the model might use different output formats at will. \n",
    "\n",
    "One thing to note is that we might have instructed the model to provide us with a nice JSON representation of extracted entities and relationships. Nicely structured data might certainly be plus. However, you are paying the price for nicely structured JSON objects as the cost of the API is calculated per input and output token count. Therefore, the JSON boilerplate comes with a price.\n",
    "\n",
    "Next, we need to define the function that calls the GPT-4 endpoint and processes the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "xL35GBGnK43H"
   },
   "outputs": [],
   "source": [
    "system = \"You are an archeology and biology expert helping us extract relevant information.\"\n",
    "\n",
    "# Set up the prompt for GPT-3 to complete\n",
    "prompt = \"\"\"#This a transcript from a sea documentary. The task is to extract as many relevant entities to biology, chemistry, or archeology.\n",
    "#The entities should include all animals, biological entities, locations.\n",
    "#However, the entities should not include distances or time durations.\n",
    "#Also, return the type of an entity using the Wikipedia class system and the sentiment of the mentioned entity,\n",
    "#where the sentiment value ranges from -1 to 1, and -1 being very negative, 1 being very positive\n",
    "#Additionally, extract all relevant relationships between identified entities.\n",
    "#The relationships should follow the Wikipedia schema type.\n",
    "#The output of a relationship should be in a form of a triple Head, Relationship, Tail, for example\n",
    "#Peter, WORKS_AT, Hospital/n\n",
    "# An example \"St. Peter is located in Paris\" should have an output with the following format\n",
    "entity\n",
    "St. Peter, person, 0.0\n",
    "Paris, location, 0.0\n",
    "\n",
    "relationships\n",
    "St.Peter, LOCATED_IN, Paris\\n\"\"\"\n",
    "\n",
    "@retry(tries=3, delay=5)\n",
    "def process_gpt4(text):\n",
    "    paragraph = text\n",
    "\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        # Try to be as deterministic as possible\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": system},\n",
    "            {\"role\": \"user\", \"content\": prompt + paragraph},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    nlp_results = completion.choices[0].message.content\n",
    "    \n",
    "    if not \"relationships\" in nlp_results:\n",
    "        raise Exception(\n",
    "            \"GPT-4 is not being nice and isn't returning results in correct format\"\n",
    "        )\n",
    "    \n",
    "    return parse_entities_and_relationships(nlp_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even though we explicitly defined the output format in the prompt, the GPT-4 model sometimes does its own thing and does follow the rules. It happened to me only twice out of a couple of hundred requests. However, it is annoying when that happens, and all the downstream dataflow doesn't work as intended. Therefore, I added a simple check of the response and added a retry decorator in case that happens.\n",
    "\n",
    "Additionally, I only added the temperature parameter to make the model behave as deterministic as possible. However, when I rerun the transcript a couple of times, I got slightly different results. It costs around $1.6 to process the transcript of the chosen video with GPT-4.\n",
    "\n",
    "## Graph model and import\n",
    "\n",
    "We will be using Neo4j to store the results of the information extraction pipeline. I have used a free Neo4j Sandbox instance for this project, but you can also use the free Aura, or local Desktop environment.\n",
    "One thing is certain. No NLP model is perfect. Therefore, we want all extracted entities and relationships to point to the text where they were extracted, which allows us to verify the validity of information if necessary.\n",
    "\n",
    "Since we want to point the extracted entities and relationships to the relevant text, we need to include the sections along with the video in our graph. The section nodes contain the text, start, and end time. Entities and relationships are then connected to the section nodes. What might be counterintuitive is that we represent extracted relationships as a node in our graph. The reason is that Neo4j doesn't allow to have relationships to point to another relationship. However, we want to have a link between extracted relationship and its source text. Therefore, we need to model the extracted relationship as a separate node."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 814
    },
    "id": "MmdQQnQReMKu",
    "outputId": "3a02a21e-e00f-4f6e-f31a-d634724896e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 0 paragraph\n",
      "Processing 1 paragraph\n",
      "Processing 2 paragraph\n",
      "Processing 3 paragraph\n",
      "Processing 4 paragraph\n",
      "Processing 5 paragraph\n",
      "Processing 6 paragraph\n",
      "Processing 7 paragraph\n",
      "Processing 8 paragraph\n",
      "Processing 9 paragraph\n",
      "Processing 10 paragraph\n",
      "Processing 11 paragraph\n",
      "Processing 12 paragraph\n",
      "Processing 13 paragraph\n",
      "Processing 14 paragraph\n",
      "Processing 15 paragraph\n",
      "Processing 16 paragraph\n",
      "Processing 17 paragraph\n",
      "Processing 18 paragraph\n",
      "Processing 19 paragraph\n",
      "Processing 20 paragraph\n",
      "Processing 21 paragraph\n",
      "Processing 22 paragraph\n",
      "Processing 23 paragraph\n",
      "Processing 24 paragraph\n",
      "Processing 25 paragraph\n",
      "Processing 26 paragraph\n",
      "Processing 27 paragraph\n",
      "Processing 28 paragraph\n",
      "Processing 29 paragraph\n",
      "Processing 30 paragraph\n",
      "Processing 31 paragraph\n",
      "Processing 32 paragraph\n",
      "Processing 33 paragraph\n",
      "Processing 34 paragraph\n",
      "Processing 35 paragraph\n",
      "Processing 36 paragraph\n",
      "Processing 37 paragraph\n",
      "Processing 38 paragraph\n",
      "Processing 39 paragraph\n",
      "Processing 40 paragraph\n",
      "Processing 41 paragraph\n",
      "Processing 42 paragraph\n",
      "Processing 43 paragraph\n",
      "Processing 44 paragraph\n",
      "Processing 45 paragraph\n",
      "Processing 46 paragraph\n",
      "Processing 47 paragraph\n",
      "Processing 48 paragraph\n",
      "Processing 49 paragraph\n",
      "Processing 50 paragraph\n",
      "Processing 51 paragraph\n",
      "Processing 52 paragraph\n",
      "Processing 53 paragraph\n",
      "Processing 54 paragraph\n",
      "Processing 55 paragraph\n",
      "Processing 56 paragraph\n",
      "Processing 57 paragraph\n",
      "Processing 58 paragraph\n",
      "Processing 59 paragraph\n",
      "Processing 60 paragraph\n",
      "Processing 61 paragraph\n",
      "Processing 62 paragraph\n",
      "Processing 63 paragraph\n",
      "Processing 64 paragraph\n",
      "Processing 65 paragraph\n",
      "Processing 66 paragraph\n",
      "Processing 67 paragraph\n",
      "Processing 68 paragraph\n",
      "Processing 69 paragraph\n",
      "Processing 70 paragraph\n",
      "Processing 71 paragraph\n",
      "Processing 72 paragraph\n",
      "Processing 73 paragraph\n",
      "Processing 74 paragraph\n",
      "Processing 75 paragraph\n",
      "Processing 76 paragraph\n"
     ]
    }
   ],
   "source": [
    "import_query = \"\"\"\n",
    "MERGE (v:Video {id:$videoId})\n",
    "CREATE (v)-[:HAS_SECTION]->(p:Section)\n",
    "SET p.startTime = toFloat($start),\n",
    "    p.endTime = toFloat($end),\n",
    "    p.text = $text\n",
    "FOREACH (e in $entities |\n",
    "  MERGE (entity:Entity {name: e[0]})\n",
    "  ON CREATE SET entity.type = e[1] \n",
    "  MERGE (p)-[:MENTIONS{sentiment:toFloat(e[2])}]->(entity))\n",
    "WITH p\n",
    "UNWIND $relationships AS relation\n",
    "MERGE (source:Entity {name: relation[0]})\n",
    "MERGE (target:Entity {name: relation[2]})\n",
    "MERGE (source)-[:RELATIONSHIP]->(r:Relationship {type: relation[1]})-[:RELATIONSHIP]->(target)\n",
    "MERGE (p)-[mr:MENTIONS_RELATIONSHIP]->(r)\n",
    "\"\"\"\n",
    "\n",
    "with driver.session() as session:\n",
    "    for i, section in enumerate(sections):\n",
    "        print(f\"Processing {i} paragraph\")\n",
    "        text = section[\"text\"]\n",
    "        start = section[\"start_time\"]\n",
    "        end = section[\"end_time\"]\n",
    "        entities, relationships = process_gpt4(text)\n",
    "        params = {\n",
    "            \"videoId\": video_id,\n",
    "            \"start\": start,\n",
    "            \"end\": end,\n",
    "            \"text\": text,\n",
    "            \"entities\": entities,\n",
    "            \"relationships\": relationships,\n",
    "        }\n",
    "        session.run(import_query, params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entity disambiguation\n",
    "\n",
    "Entity disambiguation with GPT-4\n",
    "After inspecting the GPT-4 results, I have decided that performing a simple entity disambiguation would be best. For example, there are currently five different nodes for a Moray Eels:\n",
    "\n",
    "* moray eel\n",
    "* Moray\n",
    "* Moray Eel\n",
    "* moray\n",
    "* morays\n",
    "\n",
    "We could lowercase all entities and use various NLP techniques to identify which nodes refer to the same entities. However, we can also use the GPT-4 endpoint to perform entity disambiguation. I wrote the following prompt to perform entity disambiguation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "disambiguation_prompt = \"\"\"\n",
    "#Act as a entity disambiugation tool and tell me which values reference the same entity. \n",
    "#For example if I give you\n",
    "#\n",
    "#Birds\n",
    "#Bird\n",
    "#Ant\n",
    "#\n",
    "#You return to me\n",
    "#\n",
    "#Birds, 1\n",
    "#Bird, 1\n",
    "#Ant, 2\n",
    "#\n",
    "#As the Bird and Birds values have the same integer assigned to them, it means that they reference the same entity.\n",
    "#Now process the following values\\n\n",
    "\"\"\"\n",
    "\n",
    "def disambiguate(entities):\n",
    "    completion = openai.ChatCompletion.create(\n",
    "        model=\"gpt-4\",\n",
    "        # Try to be as deterministic as possible\n",
    "        temperature=0,\n",
    "        messages=[\n",
    "            {\"role\": \"user\", \"content\": disambiguation_prompt + \"\\n\".join(all_animals)},\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    disambiguation_results = completion.choices[0].message.content\n",
    "    return [row.split(\", \") for row in disambiguation_results.split(\"\\n\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to assign the same integers to nodes that refer to the same entity. Using this prompt, we are able to tag all nodes with additional disambiguation property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_animals = run_query(\"\"\"\n",
    "MATCH (e:Entity {type: 'animal'})\n",
    "RETURN e.name AS animal\n",
    "\"\"\")['animal'].to_list()\n",
    "\n",
    "\n",
    "disambiguation_params = disambiguate(all_animals)\n",
    "run_query(\n",
    "    \"\"\"\n",
    "UNWIND $data AS row\n",
    "MATCH (e:Entity {name:row[0]})\n",
    "SET e.disambiguation = row[1]\n",
    "\"\"\",\n",
    "    {\"data\": disambiguation_params},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the disambiguation information is in the database, we can use it to evaluate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>i</th>\n",
       "      <th>entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>[moray eel, Moray, Moray Eel, moray, morays]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>[lionfish, lionfishes, Lionfish]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>[Brittle star, brittle stars, brittle star]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>[hermit crab, Hermit crab]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>[Monkfish, monkfish]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    i                                      entities\n",
       "0  22  [moray eel, Moray, Moray Eel, moray, morays]\n",
       "1  16              [lionfish, lionfishes, Lionfish]\n",
       "2   9   [Brittle star, brittle stars, brittle star]\n",
       "3   6                    [hermit crab, Hermit crab]\n",
       "4   5                          [Monkfish, monkfish]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(\"\"\"\n",
    "MATCH (e:Entity {type:\"animal\"})\n",
    "RETURN e.disambiguation AS i, collect(e.name) AS entities\n",
    "ORDER BY size(entities) DESC\n",
    "LIMIT 5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'done'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>done</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  'done'\n",
       "0   done"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(\"\"\"\n",
    "MATCH (e:Entity {type:\"animal\"})\n",
    "WITH e.disambiguation AS i, collect(e) AS entities\n",
    "CALL apoc.refactor.mergeNodes(entities, {mergeRels:True})\n",
    "YIELD node\n",
    "RETURN distinct 'done'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aKV8rtdQ3OXF"
   },
   "source": [
    "While this disambiguation is not that complicated, it is still worth noting that we can achieve this without NLP knowledge or having to develop any hand-crafted rules.\n",
    "## Analysis\n",
    "In the final step of this blog post, we will evaluate the results of the information extraction pipeline using the GPT-4 model.\n",
    "\n",
    "First, we will examine the type and count of extracted entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>animal</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>location</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>biological entity</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>biological_entity</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                type  count\n",
       "0             animal     72\n",
       "1               None     33\n",
       "2           location     31\n",
       "3  biological entity     30\n",
       "4  biological_entity     14"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(\"\"\"\n",
    "MATCH (e:Entity)\n",
    "RETURN e.type AS type, count(*) AS count\n",
    "ORDER BY count DESC\n",
    "LIMIT 5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most entities are animals, locations, and biological entities. However, we can notice that sometimes the model decides to use the whitespace and other times underscore for biological entities.\n",
    "\n",
    "Throughout my experiments with GPT endpoints, I have observed that the best approach is to be as specific as possible in what information and how you want it to be categorized. Therefore, it is good practice with GPT-4 to define the types of entities we want to extract, as the resulting types will be more consistent.\n",
    "\n",
    "Additionally, the model didn't classify 33 entity types. The thing is that GPT-4 might come up with some types for these entities if asked. However, they only appear in the relationship extraction part of the results, where entity types are not requested. One workaround could be to ask for entity types in the relationship extraction part as well.\n",
    "\n",
    "Next, we will examine which animals are the most mentioned in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "7tDw2i9z32Gn"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity</th>\n",
       "      <th>type</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>morays</td>\n",
       "      <td>animal</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lionfish</td>\n",
       "      <td>animal</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>brittle star</td>\n",
       "      <td>animal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>monkfish</td>\n",
       "      <td>animal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cardinal fish</td>\n",
       "      <td>animal</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          entity    type  mentions\n",
       "0         morays  animal         7\n",
       "1       Lionfish  animal         5\n",
       "2   brittle star  animal         3\n",
       "3       monkfish  animal         3\n",
       "4  Cardinal fish  animal         3"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(\"\"\"\n",
    "MATCH (e:Entity {type:\"animal\"})\n",
    "RETURN e.name AS entity, e.type AS type,\n",
    "       count{(e)<-[:MENTIONS]-()} AS mentions\n",
    "ORDER BY mentions DESC\n",
    "LIMIT 5\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most mentioned animals are moray eels, lionfish, and brittle stars. I am familiar only with eels, so watching the documentary to learn about other fishes might be a good idea.\n",
    "\n",
    "We can also evaluate the which relationships or facts have been extracted regarding moray eels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>relationship</th>\n",
       "      <th>target</th>\n",
       "      <th>mentions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>morays</td>\n",
       "      <td>INTERACTS_WITH</td>\n",
       "      <td>Lionfish</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>morays</td>\n",
       "      <td>HUNTS</td>\n",
       "      <td>fishes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>morays</td>\n",
       "      <td>SHARE_HOME</td>\n",
       "      <td>congareal</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>morays</td>\n",
       "      <td>HUNTS_IN</td>\n",
       "      <td>Reef</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>morays</td>\n",
       "      <td>SEARCHES_FOR</td>\n",
       "      <td>Female Moray</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>morays</td>\n",
       "      <td>STAYS_IN</td>\n",
       "      <td>Cave</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>morays</td>\n",
       "      <td>HUNTS_IN</td>\n",
       "      <td>coral head</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>morays</td>\n",
       "      <td>ABLE_TO_GET_IN</td>\n",
       "      <td>Cracks_and_Crevices</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>morays</td>\n",
       "      <td>LIVES_IN</td>\n",
       "      <td>reef</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>morays</td>\n",
       "      <td>COOPERATES_WITH</td>\n",
       "      <td>grouper</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>morays</td>\n",
       "      <td>COEXIST_WITH</td>\n",
       "      <td>Triggerfish</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>morays</td>\n",
       "      <td>VISITS</td>\n",
       "      <td>cleaner wrasses</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>grouper</td>\n",
       "      <td>COOPERATES_WITH</td>\n",
       "      <td>morays</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Cleaner Shrimps</td>\n",
       "      <td>CLEAN</td>\n",
       "      <td>morays</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>grouper</td>\n",
       "      <td>SIGNALS_TO</td>\n",
       "      <td>morays</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Nutritious Freeloaders</td>\n",
       "      <td>FOUND_ON</td>\n",
       "      <td>morays</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cleaner wrasses</td>\n",
       "      <td>CLEAN</td>\n",
       "      <td>morays</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    source     relationship               target  mentions\n",
       "0                   morays   INTERACTS_WITH             Lionfish         1\n",
       "1                   morays            HUNTS               fishes         1\n",
       "2                   morays       SHARE_HOME            congareal         1\n",
       "3                   morays         HUNTS_IN                 Reef         1\n",
       "4                   morays     SEARCHES_FOR         Female Moray         1\n",
       "5                   morays         STAYS_IN                 Cave         1\n",
       "6                   morays         HUNTS_IN           coral head         1\n",
       "7                   morays   ABLE_TO_GET_IN  Cracks_and_Crevices         1\n",
       "8                   morays         LIVES_IN                 reef         1\n",
       "9                   morays  COOPERATES_WITH              grouper         1\n",
       "10                  morays     COEXIST_WITH          Triggerfish         1\n",
       "11                  morays           VISITS      cleaner wrasses         1\n",
       "12                 grouper  COOPERATES_WITH               morays         1\n",
       "13         Cleaner Shrimps            CLEAN               morays         1\n",
       "14                 grouper       SIGNALS_TO               morays         1\n",
       "15  Nutritious Freeloaders         FOUND_ON               morays         1\n",
       "16         cleaner wrasses            CLEAN               morays         1"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(\"\"\"\n",
    "MATCH (e:Entity {name:\"morays\"})-[:RELATIONSHIP]->(r)-[:RELATIONSHIP]->(target)\n",
    "RETURN e.name AS source, r.type AS relationship, target.name AS target,\n",
    "       count{(r)<-[:MENTIONS_RELATIONSHIP]-()} AS mentions\n",
    "UNION ALL\n",
    "MATCH (e:Entity {name:\"morays\"})<-[:RELATIONSHIP]->(r)<-[:RELATIONSHIP]-(source)\n",
    "RETURN source.name AS source, r.type AS relationship, e.name AS target,\n",
    "       count{(r)<-[:MENTIONS_RELATIONSHIP]-()} AS mentions\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is quite a lot we can learn about moray eels. They cooperate with groupers, coexist with Triggerfishes, and are being cleaned by cleaner shrimps. Additionally, a moray searching for a female moray can be relatable.\n",
    "\n",
    "Let's say, for example, we want to check if the relationship that morays interact with lionfish is accurate. We can retrieve the source text and validate the claim manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ly tough are its cousins the scorpion fishes they lie there as if dead especially when others around them freak out and even when moray eels fight...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                    text\n",
       "0  ly tough are its cousins the scorpion fishes they lie there as if dead especially when others around them freak out and even when moray eels fight..."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(\"\"\"\n",
    "MATCH (e:Entity)-[:RELATIONSHIP]->(r)-[:RELATIONSHIP]->(t:Entity)\n",
    "WHERE e.name = \"morays\" AND r.type = \"INTERACTS_WITH\" AND t.name = \"Lionfish\"\n",
    "MATCH (r)<-[:MENTIONS_RELATIONSHIP]-(s:Section)\n",
    "RETURN s.text AS text\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The text mentions that eels fight with lionfish for food. We can also notice that the transcript is hard to read and understand, even for a human. Therefore, we can commend GPT-4 for doing a good job on a transcript where even a human might struggle.\n",
    "\n",
    "Lastly, we can use the knowledge graph as a search engine that returns timestamps of sections where relevant entities we want to see. So, for example, we can ask the database to return all the timestamps of sections in which lionfish is mentioned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "h-FD1GmC7u0T"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>endTime</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>648.18</td>\n",
       "      <td>667.92</td>\n",
       "      <td>https://youtube.com/watch?v=nrI483C5Tro&amp;t=648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1455.24</td>\n",
       "      <td>1498.38</td>\n",
       "      <td>https://youtube.com/watch?v=nrI483C5Tro&amp;t=1455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1514.58</td>\n",
       "      <td>1529.10</td>\n",
       "      <td>https://youtube.com/watch?v=nrI483C5Tro&amp;t=1514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1537.86</td>\n",
       "      <td>1560.48</td>\n",
       "      <td>https://youtube.com/watch?v=nrI483C5Tro&amp;t=1537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1664.64</td>\n",
       "      <td>1703.52</td>\n",
       "      <td>https://youtube.com/watch?v=nrI483C5Tro&amp;t=1664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   timestamp  endTime                                             URL\n",
       "0     648.18   667.92   https://youtube.com/watch?v=nrI483C5Tro&t=648\n",
       "1    1455.24  1498.38  https://youtube.com/watch?v=nrI483C5Tro&t=1455\n",
       "2    1514.58  1529.10  https://youtube.com/watch?v=nrI483C5Tro&t=1514\n",
       "3    1537.86  1560.48  https://youtube.com/watch?v=nrI483C5Tro&t=1537\n",
       "4    1664.64  1703.52  https://youtube.com/watch?v=nrI483C5Tro&t=1664"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_query(\"\"\"\n",
    "MATCH (e:Entity {name:\"Lionfish\"})<-[:MENTIONS]-(s:Section)<-[:HAS_SECTION]-(v:Video)\n",
    "RETURN s.startTime AS timestamp, s.endTime AS endTime,\n",
    "       \"https://youtube.com/watch?v=\" + v.id + \"&t=\" + toString(toInteger(s.startTime)) AS URL\n",
    "ORDER BY timestamp\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2eJtztS-8C-k"
   },
   "source": [
    "## Summary\n",
    "The remarkable ability of GPT-3.5 and GPT-4 models to generalize across various domains is a powerful tool for exploring and analyzing different datasets to extract relevant information. In all honesty, I'm not entirely sure which endpoint I would use to recreate this blog post without GPT-4. As far as I know, there are no open-source relation extraction models or datasets on sea creatures. Therefore, to avoid the hassle of labeling a dataset and training a custom model, we can simply utilize a GPT endpoint. Furthermore, I'm eagerly anticipating the opportunity to examine its promised capability for multi-modal analysis based on audio or text input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO2LGaGlfbtzZJWxfJzh3tc",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
